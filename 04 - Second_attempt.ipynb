{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVZ+uOIklrWmK3e41ke0wg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosMejia07/Proyecto-Kaggle-UdeA-20252/blob/main/04%20-%20Second_attempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**En este modelo se usa el preprocesado de la segunda entrega y la predicción con RandomForestClassifier. Puntaje = 0.38973**"
      ],
      "metadata": {
        "id": "7aKCPF_V_xCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importe, descompresión e inspección de los datos**"
      ],
      "metadata": {
        "id": "326-pPG0_0ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSSUPHhm_TyP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!chmod 600 ./kaggle.json\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n",
        "!unzip udea*.zip > /dev/null\n",
        "!wc *.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importe de las librerias a usar y lectura del archivo train**"
      ],
      "metadata": {
        "id": "vzFBY3nEADBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "z = pd.read_csv(\"train.csv\")\n",
        "print (\"Estructura de los datos cargados\", z.shape)\n",
        "z_clean = z.copy()"
      ],
      "metadata": {
        "id": "KXXlRHegAJPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocesado de train**"
      ],
      "metadata": {
        "id": "FTiF9tpEAO9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se dejan de lado las columnas que no aporten a la predicción, preliminarmente\n",
        "z_clean = z_clean.drop(columns=['ID', 'PERIODO_ACADEMICO'])\n",
        "\n",
        "#Detección y reemplazo de valores nulos\n",
        "# Separar valores numéricos y no numéricos\n",
        "numeric_cols = z_clean.select_dtypes(include=np.number).columns\n",
        "non_numeric_cols = z_clean.select_dtypes(exclude=np.number).columns\n",
        "\n",
        "# Reemplazar valores nulos de columnas numéricas con la media\n",
        "z_clean[numeric_cols] = z_clean[numeric_cols].fillna(z_clean[numeric_cols].median())\n",
        "\n",
        "# Reemplazar valores nulos de columnas no numéricas por la moda\n",
        "for col in non_numeric_cols:\n",
        "    z_clean[col] = z_clean[col].fillna(z_clean[col].mode()[0])\n",
        "\n",
        "z_clean.isna().sum()\n",
        "\n",
        "#Codificación de las variables con valores nominales y ordinales\n",
        "def replace_binary(col):\n",
        "    return col.replace({\n",
        "        'Si': 1, 'Sí': 1, 'S': 1, 'Y': 1, '1': 1, 'si': 1, 'sí': 1,\n",
        "        'No': 0, 'N': 0, '0': 0, 'no': 0\n",
        "    })\n",
        "\n",
        "binary_cols = ['F_TIENEINTERNET', 'F_TIENELAVADORA', 'F_TIENEAUTOMOVIL',\n",
        "               'E_PRIVADO_LIBERTAD', 'E_PAGOMATRICULAPROPIO', 'F_TIENECOMPUTADOR',\n",
        "               'F_TIENEINTERNET.1']\n",
        "\n",
        "for col in binary_cols:\n",
        "    z_clean[col] = replace_binary(z_clean[col])\n",
        "\n",
        "z_clean[binary_cols] = z_clean[binary_cols].astype(int)\n",
        "\n",
        "# Reemplazar valores de variables ordinales\n",
        "z_clean['F_EDUCACIONPADRE'] = z_clean['F_EDUCACIONPADRE'].replace(['No sabe', 'No Aplica'], 'Desconocido')\n",
        "z_clean['F_EDUCACIONMADRE'] = z_clean['F_EDUCACIONMADRE'].replace(['No sabe', 'No Aplica'], 'Desconocido')\n",
        "\n",
        "orden_educacion = [\n",
        "    'Desconocido',\n",
        "    'Ninguno',\n",
        "    'Primaria incompleta',\n",
        "    'Primaria completa',\n",
        "    'Secundaria (Bachillerato) incompleta',\n",
        "    'Secundaria (Bachillerato) completa',\n",
        "    'Técnica o tecnológica incompleta',\n",
        "    'Técnica o tecnológica completa',\n",
        "    'Educación profesional incompleta',\n",
        "    'Educación profesional completa',\n",
        "    'Postgrado'\n",
        "]\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "encoder = OrdinalEncoder(categories=[orden_educacion])\n",
        "z_clean['F_EDUCACIONPADRE'] = encoder.fit_transform(z_clean[['F_EDUCACIONPADRE']])\n",
        "z_clean['F_EDUCACIONMADRE'] = encoder.fit_transform(z_clean[['F_EDUCACIONMADRE']])\n",
        "\n",
        "orden_matrícula = [\n",
        "    'No pagó matrícula',\n",
        "    'Menos de 500 mil',\n",
        "    'Entre 500 mil y menos de 1 millón',\n",
        "    'Entre 1 millón y menos de 2.5 millones',\n",
        "    'Entre 2.5 millones y menos de 4 millones',\n",
        "    'Entre 4 millones y menos de 5.5 millones',\n",
        "    'Entre 5.5 millones y menos de 7 millones',\n",
        "    'Más de 7 millones'\n",
        "]\n",
        "encoder = OrdinalEncoder(categories=[orden_matrícula])\n",
        "z_clean['E_VALORMATRICULAUNIVERSIDAD'] = encoder.fit_transform(z_clean[['E_VALORMATRICULAUNIVERSIDAD']])\n",
        "\n",
        "orden_estrato = [\n",
        "    'Sin Estrato',\n",
        "    'Estrato 1',\n",
        "    'Estrato 2',\n",
        "    'Estrato 3',\n",
        "    'Estrato 4',\n",
        "    'Estrato 5',\n",
        "    'Estrato 6'\n",
        "]\n",
        "encoder = OrdinalEncoder(categories=[orden_estrato])\n",
        "z_clean['F_ESTRATOVIVIENDA'] = encoder.fit_transform(z_clean[['F_ESTRATOVIVIENDA']])\n",
        "\n",
        "orden_trabajo = [\n",
        "    '0',\n",
        "    'Menos de 10 horas',\n",
        "    'Entre 11 y 20 horas',\n",
        "    'Entre 21 y 30 horas',\n",
        "    'Más de 30 horas'\n",
        "]\n",
        "encoder = OrdinalEncoder(categories=[orden_trabajo])\n",
        "z_clean['E_HORASSEMANATRABAJA'] = encoder.fit_transform(z_clean[['E_HORASSEMANATRABAJA']])\n",
        "\n",
        "#Ahora las variables nominales (no tienen orden específico)\n",
        "# Se realiza un One-Hot Encoding\n",
        "z_clean = pd.get_dummies(z_clean, columns=['E_PRGM_DEPARTAMENTO', 'E_PRGM_ACADEMICO'])\n",
        "\n",
        "# Guarda las columnas de X\n",
        "X = z_clean.drop(columns=['RENDIMIENTO_GLOBAL'])\n",
        "train_columns = X.columns\n",
        "\n",
        "#Estandarizado de las variables ordinales, necesario o no según el o los modelos que se usarán\n",
        "# Con media = 0, desviación estándar = 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "cols_ordinales = ['E_HORASSEMANATRABAJA', 'F_ESTRATOVIVIENDA',\n",
        "                  'E_VALORMATRICULAUNIVERSIDAD', 'F_EDUCACIONPADRE', 'F_EDUCACIONMADRE']\n",
        "\n",
        "z_clean[cols_ordinales] = scaler.fit_transform(z_clean[cols_ordinales])\n",
        "\n",
        "# Variables numéricas\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "cols_numericas = ['INDICADOR_1', 'INDICADOR_2', 'INDICADOR_3', 'INDICADOR_4']\n",
        "\n",
        "z_clean[cols_numericas] = scaler.fit_transform(z_clean[cols_numericas])\n",
        "\n",
        "#Variable objetivo\n",
        "# Definimos el orden lógico\n",
        "orden = ['bajo', 'medio-bajo', 'medio-alto', 'alto']\n",
        "\n",
        "z_clean['RENDIMIENTO_GLOBAL'] = pd.Categorical(\n",
        "    z_clean['RENDIMIENTO_GLOBAL'],\n",
        "    categories=orden,\n",
        "    ordered=True\n",
        ").codes\n",
        "\n",
        "# Visualización de los datos\n",
        "z_clean.head(10)"
      ],
      "metadata": {
        "id": "k54rwXVQAcIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_cols = X.select_dtypes(include='object').columns\n",
        "print(object_cols)"
      ],
      "metadata": {
        "id": "eKxcP_95CF6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Modelado***"
      ],
      "metadata": {
        "id": "OECrDUZwBg-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Variable predictoria y objetivo\n",
        "X = z_clean.drop(columns=['RENDIMIENTO_GLOBAL'])\n",
        "y = z_clean['RENDIMIENTO_GLOBAL']\n",
        "\n",
        "#Dividir dataset para entrenar y validar el modelo\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "#entrenar con catboost\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "model = CatBoostClassifier(\n",
        "    iterations=500,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    verbose=100\n",
        ")\n",
        "model.fit(X_train, y_train, eval_set=(X_val, y_val))"
      ],
      "metadata": {
        "id": "7cTyRlZFBxLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "QESRguKBCxI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carga y preprocesado de los datos del archivo test**"
      ],
      "metadata": {
        "id": "23Iy-RilC5GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"test.csv\")\n",
        "test_ids = test[\"ID\"]  # Guardamos los IDs como referencia\n",
        "test_clean = test.copy()\n",
        "\n",
        "test_clean = test_clean.drop(columns=['ID', 'PERIODO_ACADEMICO'])\n",
        "\n",
        "# Separar valores numéricos y no numéricos\n",
        "numeric_cols = test_clean.select_dtypes(include=np.number).columns\n",
        "non_numeric_cols = test_clean.select_dtypes(exclude=np.number).columns\n",
        "\n",
        "# Reemplazar valores nulos de columnas numéricas con la media\n",
        "test_clean[numeric_cols] = test_clean[numeric_cols].fillna(test_clean[numeric_cols].median())\n",
        "\n",
        "# Reemplazar valores nulos de columnas no numéricas por la moda\n",
        "for col in non_numeric_cols:\n",
        "    test_clean[col] = test_clean[col].fillna(test_clean[col].mode()[0])\n",
        "\n",
        "test_clean.isna().sum()\n",
        "\n",
        "# Reemplazar valores si & no por 0 & 1\n",
        "def replace_binary(col):\n",
        "    return col.replace({\n",
        "        'Si': 1, 'Sí': 1, 'S': 1, 'Y': 1, '1': 1, 'si': 1, 'sí': 1,\n",
        "        'No': 0, 'N': 0, '0': 0, 'no': 0\n",
        "    })\n",
        "\n",
        "binary_cols = ['F_TIENEINTERNET', 'F_TIENELAVADORA', 'F_TIENEAUTOMOVIL',\n",
        "               'E_PRIVADO_LIBERTAD', 'E_PAGOMATRICULAPROPIO', 'F_TIENECOMPUTADOR',\n",
        "               'F_TIENEINTERNET.1']\n",
        "\n",
        "for col in binary_cols:\n",
        "    test_clean[col] = replace_binary(test_clean[col])\n",
        "\n",
        "test_clean[binary_cols] = test_clean[binary_cols].astype(int)\n",
        "\n",
        "# Reemplazar valores de variables ordinales\n",
        "test_clean['F_EDUCACIONPADRE'] = test_clean['F_EDUCACIONPADRE'].replace(['No sabe', 'No Aplica'], 'Desconocido')\n",
        "test_clean['F_EDUCACIONMADRE'] = test_clean['F_EDUCACIONMADRE'].replace(['No sabe', 'No Aplica'], 'Desconocido')\n",
        "\n",
        "orden_educacion = [\n",
        "    'Desconocido',\n",
        "    'Ninguno',\n",
        "    'Primaria incompleta',\n",
        "    'Primaria completa',\n",
        "    'Secundaria (Bachillerato) incompleta',\n",
        "    'Secundaria (Bachillerato) completa',\n",
        "    'Técnica o tecnológica incompleta',\n",
        "    'Técnica o tecnológica completa',\n",
        "    'Educación profesional incompleta',\n",
        "    'Educación profesional completa',\n",
        "    'Postgrado'\n",
        "]\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "encoder = OrdinalEncoder(categories=[orden_educacion])\n",
        "test_clean['F_EDUCACIONPADRE'] = encoder.fit_transform(test_clean[['F_EDUCACIONPADRE']])\n",
        "test_clean['F_EDUCACIONMADRE'] = encoder.fit_transform(test_clean[['F_EDUCACIONMADRE']])\n",
        "\n",
        "orden_matrícula = [\n",
        "    'No pagó matrícula',\n",
        "    'Menos de 500 mil',\n",
        "    'Entre 500 mil y menos de 1 millón',\n",
        "    'Entre 1 millón y menos de 2.5 millones',\n",
        "    'Entre 2.5 millones y menos de 4 millones',\n",
        "    'Entre 4 millones y menos de 5.5 millones',\n",
        "    'Entre 5.5 millones y menos de 7 millones',\n",
        "    'Más de 7 millones'\n",
        "]\n",
        "encoder = OrdinalEncoder(categories=[orden_matrícula])\n",
        "test_clean['E_VALORMATRICULAUNIVERSIDAD'] = encoder.fit_transform(test_clean[['E_VALORMATRICULAUNIVERSIDAD']])\n",
        "\n",
        "orden_estrato = [\n",
        "    'Sin Estrato',\n",
        "    'Estrato 1',\n",
        "    'Estrato 2',\n",
        "    'Estrato 3',\n",
        "    'Estrato 4',\n",
        "    'Estrato 5',\n",
        "    'Estrato 6'\n",
        "]\n",
        "encoder = OrdinalEncoder(categories=[orden_estrato])\n",
        "test_clean['F_ESTRATOVIVIENDA'] = encoder.fit_transform(test_clean[['F_ESTRATOVIVIENDA']])\n",
        "\n",
        "orden_trabajo = [\n",
        "    '0',\n",
        "    'Menos de 10 horas',\n",
        "    'Entre 11 y 20 horas',\n",
        "    'Entre 21 y 30 horas',\n",
        "    'Más de 30 horas'\n",
        "]\n",
        "encoder = OrdinalEncoder(categories=[orden_trabajo])\n",
        "test_clean['E_HORASSEMANATRABAJA'] = encoder.fit_transform(test_clean[['E_HORASSEMANATRABAJA']])\n",
        "\n",
        "# Se realiza un One-Hot Encoding\n",
        "test_clean = pd.get_dummies(test_clean, columns=['E_PRGM_DEPARTAMENTO', 'E_PRGM_ACADEMICO'])\n",
        "\n",
        "# Esto asegura que test tenga las mismas columnas que train, en el mismo orden.\n",
        "test_clean = test_clean.reindex(columns=train_columns, fill_value=0)\n",
        "\n",
        "# Con media = 0, desviación estándar = 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "cols_ordinales = ['E_HORASSEMANATRABAJA', 'F_ESTRATOVIVIENDA',\n",
        "                  'E_VALORMATRICULAUNIVERSIDAD', 'F_EDUCACIONPADRE', 'F_EDUCACIONMADRE']\n",
        "\n",
        "test_clean[cols_ordinales] = scaler.fit_transform(test_clean[cols_ordinales])\n",
        "\n",
        "# Variables numéricas\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "cols_numericas = ['INDICADOR_1', 'INDICADOR_2', 'INDICADOR_3', 'INDICADOR_4']\n",
        "\n",
        "test_clean[cols_numericas] = scaler.fit_transform(test_clean[cols_numericas])"
      ],
      "metadata": {
        "id": "xUjn_9r7C7kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicciones**"
      ],
      "metadata": {
        "id": "IPA9apAhDJQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(test_clean)"
      ],
      "metadata": {
        "id": "i2VV7QPCDNHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparando el archivo solución**"
      ],
      "metadata": {
        "id": "NYq-gs9EDP0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_dict = {0: 'bajo', 1: 'medio-bajo', 2: 'medio-alto', 3: 'alto'}\n",
        "test_predictions_cat = [map_dict[i] for i in test_predictions]\n",
        "\n",
        "solucion = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': test_predictions_cat\n",
        "})\n",
        "solucion.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "0XrmnGAxDTKm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}